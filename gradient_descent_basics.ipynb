{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 3,
            "source": [
                "import numpy as np\n",
                "\n",
                "from typing import List"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "source": [
                "# Calculating gradient with vanilla python for equation `y=mx+b`; where m & b are the parameters\n",
                "\n",
                "# Dummy training date.\n",
                "x = np.array([1, 2, 3, 4, 5])\n",
                "y  = np.array([5,7,9,11,13])"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# We'll start out with both the slope and intercept as 0 \n",
                "def gradient_descent(x: List[int], y: List[int], epochs: int = 1000):\n",
                "    current_m = current_b = 0\n",
                "    learing_rate: float = 0.01\n",
                "    n = len(x)\n",
                "\n",
                "    for epoch in range(epochs):\n",
                "        # calculate the y_predicted value using `y = mx + b`\n",
                "        y_predicted = current_m * x + current_b\n",
                "        diff_array = np.array(y - y_predicted)\n",
                "\n",
                "        # We'll use the mean squared error cost function\n",
                "        cost_function = (1/n) * sum((v**2 for v in diff_array))        \n",
                "\n",
                "        # calculate partial derivates using that\n",
                "        # Partial derivates will give us the step we need to take to minimize the cost function\n",
                "\n",
                "        m_pd = -(2 / n) * sum(x *  diff_array)\n",
                "        b_pd = -(2 / n) * sum(diff_array)\n",
                "\n",
                "        current_m = current_m - (learing_rate * m_pd)\n",
                "        current_b = current_b - (learing_rate * b_pd)\n",
                "\n",
                "        print(f\"m: {current_m}, b: {current_b}, cost: {cost_function}, epoch: {epoch + 1}\\n\")\n",
                "\n",
                "gradient_descent(x, y)\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.9.5",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.9.5 64-bit"
        },
        "interpreter": {
            "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
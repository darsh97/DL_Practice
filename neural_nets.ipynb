{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 18,
            "source": [
                "\"\"\"\n",
                "Basics of vannila neural network.\n",
                "\n",
                "Based on Sentdex's neural network playlist: https://www.youtube.com/playlist?list=PLQVvvaa0QuDcjD5BAw2DxE6OF2tius3V3\n",
                "\"\"\""
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "\"\\nBasics of vannila neural network.\\n\\nBased on Sentdex's neural network playlist: https://www.youtube.com/playlist?list=PLQVvvaa0QuDcjD5BAw2DxE6OF2tius3V3\\n\""
                        ]
                    },
                    "metadata": {},
                    "execution_count": 18
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 37,
            "source": [
                "import numpy as np  \n",
                "\n",
                "from typing import List"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 46,
            "source": [
                "\n",
                "n_input_layer = 4\n",
                "n_neurons = 3\n",
                "\n",
                "# initially weights have to be random within some range, the lesser the range the better.\n",
                "# 3 sets of weights, with each having len(x) columns.\n",
                "activation = np.array([1, 2, 3, 4.5])\n",
                "weights    = np.array(np.random.rand(n_neurons, n_input_layer))\n",
                "biases     = np.array([4, 5, 6])\n",
                "\n",
                "print(f\"activation = {activation}\\n\")\n",
                "print(f\"weights = {weights}\\n\")\n",
                "print(f\"biases = {biases}\\n\")"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "activation = [1.  2.  3.  4.5]\n",
                        "\n",
                        "weights = [[0.13786524 0.08911181 0.17372108 0.31248231]\n",
                        " [0.83691474 0.78526225 0.32430536 0.08954182]\n",
                        " [0.09672035 0.74665453 0.36129682 0.72485405]]\n",
                        "\n",
                        "biases = [4 5 6]\n",
                        "\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 47,
            "source": [
                "\"\"\"\n",
                "The input layer has 4 neurons\n",
                "The next layer has 3 neurons\n",
                "\n",
                "for every neuron perform => Y = (weight * activation) + bias\n",
                "\"\"\"\n",
                "\n",
                "# Simulating a single forward pass.\n",
                "# for every neuron in the input layer.\n",
                "    # get the respective weights and biases of the neuron for next layer\n",
                "    # multiply weights and activation and add bias\n",
                "\n",
                "\n",
                "output_array: List[float] = []\n",
                "\n",
                "for n in range(n_neurons):\n",
                "    current_weight_set = weights[n]\n",
                "    current_bias = biases[n]\n",
                "\n",
                "    current_output = 0\n",
                "\n",
                "    for a, w in zip(activation, current_weight_set):\n",
                "        current_output += w * a\n",
                "    \n",
                "    current_output += current_bias\n",
                "    output_array.append(current_output)\n",
                "\n",
                "print(np.array(output_array))\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "[ 6.24342252  8.78329351 11.93576311]\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 48,
            "source": [
                "# Simulating simple single forward pass with numpy dot product.\n",
                "\n",
                "output_array = np.dot(weights, activation) + biases\n",
                "print(np.array(output_array))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "[ 6.24342252  8.78329351 11.93576311]\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 49,
            "source": [
                "# We used a single set of activation.\n",
                "# Ideally, we would have several batches of them.\n",
                "\n",
                "n_neurons = 3\n",
                "n_activation = 4\n",
                "\n",
                "\n",
                "activation_set = [\n",
                "    [1, 2, 3, 4], \n",
                "    [2.2, 5.2, 1, 5.5], \n",
                "    [6.3, 1, 5, 6]\n",
                "]\n",
                "\n",
                "weight_set = np.random.rand(n_neurons, n_activation)\n",
                "biases = np.zeros(n_neurons)\n",
                "\n",
                "print(f\"activation = {np.array(activation_set)}\\n\")\n",
                "print(f\"weights = {np.array(weight_set)}\\n\")\n",
                "print(f\"biases = {np.array(biases)}\\n\")"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "activation = [[1.  2.  3.  4. ]\n",
                        " [2.2 5.2 1.  5.5]\n",
                        " [6.3 1.  5.  6. ]]\n",
                        "\n",
                        "weights = [[0.30559297 0.2884694  0.10262371 0.04040817]\n",
                        " [0.23676885 0.52056363 0.11930513 0.17289563]\n",
                        " [0.59867979 0.60765936 0.58573447 0.0369572 ]]\n",
                        "\n",
                        "biases = [0. 0. 0.]\n",
                        "\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 44,
            "source": [
                "# Simulating forward pass with batch inputs.\n",
                "\n",
                "# for every neuron\n",
                "    # pick the current activation batch\n",
                "    # process the activation batch for every weight_set\n",
                "\n",
                "\n",
                "output_array: List[List[float]] = []\n",
                "\n",
                "for n in range(n_neurons):\n",
                "    current_activation    = activation_set[n]\n",
                "    current_bias          = biases[n]\n",
                "    current_neuron_output = []\n",
                "\n",
                "    for current_weights in weight_set:\n",
                "        \n",
                "        output = 0\n",
                "        \n",
                "        for a, w in zip(current_activation, current_weights):\n",
                "            output += a * w\n",
                "\n",
                "        output += current_bias\n",
                "        current_neuron_output.append(output)\n",
                "    \n",
                "    output_array.append(current_neuron_output)\n",
                "\n",
                "print(np.array(output_array))\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "[[ 6.17949219  6.14209142  6.3069362 ]\n",
                        " [ 8.32494286  9.57070274  7.46557765]\n",
                        " [ 8.11313258 10.39524648 10.11814745]]\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 45,
            "source": [
                "# Simulating forward pass with batch inputs. (numpy dot product).\n",
                "\n",
                "output_array = np.dot(activation_set, np.array(weight_set).T) + biases \n",
                "print(output_array)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "[[ 6.17949219  6.14209142  6.3069362 ]\n",
                        " [ 8.32494286  9.57070274  7.46557765]\n",
                        " [ 8.11313258 10.39524648 10.11814745]]\n"
                    ]
                }
            ],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.9.5",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.9.5 64-bit"
        },
        "interpreter": {
            "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}